{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# OpenFedLLM è”é‚¦å­¦ä¹ è®­ç»ƒ - Google Colabç‰ˆæœ¬\n",
    "\n",
    "æœ¬notebookç”¨äºåœ¨Google Colabä¸Šè¿è¡Œè”é‚¦å­¦ä¹ è®­ç»ƒï¼Œæ— éœ€GPT APIè¯„ä¼°ã€‚\n",
    "\n",
    "## ä½¿ç”¨è¯´æ˜\n",
    "1. åœ¨Colabä¸­è¿è¡Œæ—¶ï¼Œç¡®ä¿é€‰æ‹©GPUè¿è¡Œæ—¶ï¼ˆè¿è¡Œæ—¶ -> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ -> GPUï¼‰\n",
    "2. æŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰cell\n",
    "3. è®­ç»ƒå®Œæˆåå¯ä»¥æŸ¥çœ‹è®­ç»ƒæŸå¤±æ›²çº¿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## æ­¥éª¤1: å®‰è£…ä¾èµ–åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# å®‰è£…æ ¸å¿ƒä¾èµ–ï¼ˆColabä¼˜åŒ–ç‰ˆæœ¬ï¼‰\n",
    "!pip install -q transformers==4.31.0\n",
    "!pip install -q peft==0.4.0\n",
    "!pip install -q trl==0.7.2\n",
    "!pip install -q bitsandbytes==0.40.2\n",
    "!pip install -q accelerate==0.21.0\n",
    "!pip install -q datasets==2.13.0\n",
    "!pip install -q torch==2.0.1\n",
    "!pip install -q tqdm numpy\n",
    "\n",
    "print(\"âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone"
   },
   "source": [
    "## æ­¥éª¤2: å…‹éš†ä»£ç åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# å…‹éš†ä»“åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰\n",
    "if not os.path.exists('OpenFedLLM-Attack'):\n",
    "    !git clone --recursive --shallow-submodules https://github.com/rui-ye/OpenFedLLM.git OpenFedLLM-Attack\n",
    "    print(\"âœ… ä»£ç åº“å…‹éš†å®Œæˆï¼\")\n",
    "else:\n",
    "    print(\"âœ… ä»£ç åº“å·²å­˜åœ¨ï¼Œè·³è¿‡å…‹éš†\")\n",
    "\n",
    "# è¿›å…¥é¡¹ç›®ç›®å½•\n",
    "os.chdir('OpenFedLLM-Attack')\n",
    "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## æ­¥éª¤3: è®¾ç½®ç¯å¢ƒå˜é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_env"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# è®¾ç½®PYTHONPATH\n",
    "fingpt_dir = 'evaluation/FinGPT'\n",
    "if os.path.exists(fingpt_dir):\n",
    "    sys.path.insert(0, os.path.abspath(fingpt_dir))\n",
    "\n",
    "# å°†å½“å‰ç›®å½•æ·»åŠ åˆ°Pythonè·¯å¾„\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "print(\"âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆï¼\")\n",
    "print(f\"Pythonè·¯å¾„: {sys.path[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_gpu"
   },
   "source": [
    "## æ­¥éª¤4: æ£€æŸ¥GPUå’ŒCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu_cuda"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "    print(f\"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ°GPUï¼Œè¯·ç¡®ä¿åœ¨Colabä¸­é€‰æ‹©äº†GPUè¿è¡Œæ—¶ï¼\")\n",
    "    print(\"   è®¾ç½®æ–¹æ³•: è¿è¡Œæ—¶ -> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ -> ç¡¬ä»¶åŠ é€Ÿå™¨ -> GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## æ­¥éª¤5: é…ç½®è®­ç»ƒå‚æ•°ï¼ˆé€‚åˆColabçš„å°è§„æ¨¡é…ç½®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_config"
   },
   "outputs": [],
   "source": [
    "# ========== è®­ç»ƒå‚æ•°é…ç½® ==========\n",
    "# è¿™äº›å‚æ•°å·²ç»ä¼˜åŒ–ä¸ºé€‚åˆColabçš„èµ„æºé™åˆ¶\n",
    "\n",
    "training_config = {\n",
    "    # æ¨¡å‹é…ç½®\n",
    "    'model_name_or_path': 'meta-llama/Llama-2-7b-hf',  # åŸºç¡€æ¨¡å‹\n",
    "    'use_peft': True,  # ä½¿ç”¨LoRAï¼ˆå¿…é¡»ï¼‰\n",
    "    'peft_lora_r': 16,  # LoRA rankï¼ˆé™ä½ä»¥èŠ‚çœæ˜¾å­˜ï¼‰\n",
    "    'peft_lora_alpha': 32,  # LoRA alpha\n",
    "    'load_in_8bit': True,  # 8bité‡åŒ–ï¼ˆå¿…é¡»ï¼ŒèŠ‚çœæ˜¾å­˜ï¼‰\n",
    "    \n",
    "    # æ•°æ®é›†é…ç½®\n",
    "    'dataset_name': 'vicgalle/alpaca-gpt4',  # æ•°æ®é›†\n",
    "    'dataset_sample': 5000,  # ä½¿ç”¨5000ä¸ªæ ·æœ¬ï¼ˆå‡å°‘æ•°æ®é‡ï¼‰\n",
    "    'template': 'alpaca',  # æ¨¡æ¿\n",
    "    \n",
    "    # è”é‚¦å­¦ä¹ é…ç½®\n",
    "    'fed_alg': 'fedavg',  # è”é‚¦å­¦ä¹ ç®—æ³•\n",
    "    'num_clients': 5,  # å®¢æˆ·ç«¯æ•°é‡ï¼ˆå‡å°‘ï¼‰\n",
    "    'sample_clients': 2,  # æ¯è½®é‡‡æ ·å®¢æˆ·ç«¯æ•°\n",
    "    'num_rounds': 10,  # è®­ç»ƒè½®æ•°ï¼ˆå‡å°‘ç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰\n",
    "    \n",
    "    # è®­ç»ƒé…ç½®\n",
    "    'max_steps': 5,  # æ¯è½®æ¯ä¸ªå®¢æˆ·ç«¯çš„è®­ç»ƒæ­¥æ•°ï¼ˆå‡å°‘ï¼‰\n",
    "    'batch_size': 4,  # æ‰¹æ¬¡å¤§å°ï¼ˆé™ä½ä»¥èŠ‚çœæ˜¾å­˜ï¼‰\n",
    "    'gradient_accumulation_steps': 4,  # æ¢¯åº¦ç´¯ç§¯ï¼ˆä¿æŒæœ‰æ•ˆbatch sizeï¼‰\n",
    "    'learning_rate': 2e-5,  # å­¦ä¹ ç‡\n",
    "    'seq_length': 256,  # åºåˆ—é•¿åº¦ï¼ˆé™ä½ä»¥èŠ‚çœæ˜¾å­˜ï¼‰\n",
    "    \n",
    "    # è¾“å‡ºé…ç½®\n",
    "    'output_dir': './output_colab',  # è¾“å‡ºç›®å½•\n",
    "    'save_model_freq': 5,  # æ¯5è½®ä¿å­˜ä¸€æ¬¡æ¨¡å‹\n",
    "    'logging_steps': 10,  # æ—¥å¿—æ­¥æ•°\n",
    "    'seed': 2023,  # éšæœºç§å­\n",
    "}\n",
    "\n",
    "print(\"âœ… è®­ç»ƒå‚æ•°é…ç½®å®Œæˆï¼\")\n",
    "print(\"\\né…ç½®æ‘˜è¦:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prepare_args"
   },
   "source": [
    "## æ­¥éª¤6: å‡†å¤‡å‘½ä»¤è¡Œå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prepare_arguments"
   },
   "outputs": [],
   "source": [
    "# æ„å»ºå‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨\n",
    "args_list = ['main_sft.py']  # è„šæœ¬åç§°\n",
    "\n",
    "# æ·»åŠ æ‰€æœ‰å‚æ•°\n",
    "for key, value in training_config.items():\n",
    "    if isinstance(value, bool):\n",
    "        if value:\n",
    "            args_list.append(f\"--{key}\")\n",
    "    else:\n",
    "        args_list.append(f\"--{key}\")\n",
    "        args_list.append(str(value))\n",
    "\n",
    "# æ·»åŠ è”é‚¦å­¦ä¹ ç‰¹å®šå‚æ•°ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰\n",
    "if '--save_model_freq' not in args_list:\n",
    "    args_list.extend([\n",
    "        '--save_model_freq', str(training_config['save_model_freq']),\n",
    "    ])\n",
    "\n",
    "print(\"âœ… å‘½ä»¤è¡Œå‚æ•°å‡†å¤‡å®Œæˆï¼\")\n",
    "print(f\"\\nå°†æ‰§è¡Œçš„å‘½ä»¤:\")\n",
    "print(f\"python {' '.join(args_list)}\")\n",
    "print(f\"\\nå‚æ•°æ•°é‡: {len(args_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## æ­¥éª¤7: å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_training"
   },
   "outputs": [],
   "source": [
    "# æ„å»ºå®Œæ•´çš„å‘½ä»¤å­—ç¬¦ä¸²\n",
    "cmd_args = args_list[1:]  # ç§»é™¤è„šæœ¬åç§°\n",
    "cmd_str = ' '.join([str(arg) for arg in cmd_args])\n",
    "\n",
    "print(\"ğŸš€ å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ...\")\n",
    "print(\"â° é¢„è®¡æ—¶é—´: æ ¹æ®GPUæ€§èƒ½ï¼Œå¯èƒ½éœ€è¦30åˆ†é’Ÿåˆ°2å°æ—¶\")\n",
    "print(f\"\\næ‰§è¡Œå‘½ä»¤: python main_sft.py {cmd_str[:100]}...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nè¯·åœ¨ä¸‹é¢çš„cellä¸­æ‰§è¡Œè®­ç»ƒå‘½ä»¤ï¼ˆä½¿ç”¨!pythonï¼‰\")\n",
    "print(\"\\næˆ–è€…å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç è‡ªåŠ¨æ‰§è¡Œ:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_training_exec"
   },
   "outputs": [],
   "source": [
    "# æ‰§è¡Œè®­ç»ƒå‘½ä»¤\n",
    "# æ³¨æ„ï¼šåœ¨Colabä¸­ï¼Œä½¿ç”¨!å‘½ä»¤æ‰§è¡ŒPythonè„šæœ¬æ˜¯æœ€å¯é çš„æ–¹æ³•\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"æ­£åœ¨æ‰§è¡Œè®­ç»ƒ...\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    # ä½¿ç”¨subprocessæ‰§è¡Œ\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, 'main_sft.py'] + cmd_args,\n",
    "        check=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… è®­ç»ƒå®Œæˆï¼\")\n",
    "    else:\n",
    "        print(f\"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¿”å›ç : {result.returncode}\")\n",
    "        print(\"\\nğŸ’¡ å¦‚æœsubprocesså¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤:\")\n",
    "        print(f\"!python main_sft.py {cmd_str}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ‰§è¡Œå‡ºé”™: {e}\")\n",
    "    print(\"\\nğŸ’¡ è¯·æ‰‹åŠ¨æ‰§è¡Œä¸‹é¢çš„å‘½ä»¤:\")\n",
    "    print(f\"!python main_sft.py {cmd_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## æ­¥éª¤8: å¯è§†åŒ–è®­ç»ƒæŸå¤±ï¼ˆæ— éœ€APIï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_loss"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# åŠ è½½è®­ç»ƒæŸå¤±\n",
    "loss_file = os.path.join(training_config['output_dir'], 'training_loss.npy')\n",
    "\n",
    "if os.path.exists(loss_file):\n",
    "    training_loss = np.load(loss_file)\n",
    "    \n",
    "    print(f\"è®­ç»ƒæŸå¤±å½¢çŠ¶: {training_loss.shape}\")\n",
    "    print(f\"å®¢æˆ·ç«¯æ•°é‡: {training_loss.shape[0]}\")\n",
    "    print(f\"è®­ç»ƒè½®æ•°: {training_loss.shape[1]}\")\n",
    "    \n",
    "    # ç»˜åˆ¶æŸå¤±æ›²çº¿\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # ç»˜åˆ¶æ¯ä¸ªå®¢æˆ·ç«¯çš„æŸå¤±\n",
    "    for client_id in range(training_loss.shape[0]):\n",
    "        client_loss = training_loss[client_id]\n",
    "        # è¿‡æ»¤æ‰-1ï¼ˆæœªå‚ä¸è®­ç»ƒçš„è½®æ¬¡ï¼‰\n",
    "        valid_rounds = np.where(client_loss >= 0)[0]\n",
    "        if len(valid_rounds) > 0:\n",
    "            plt.plot(valid_rounds + 1, client_loss[valid_rounds], \n",
    "                    alpha=0.6, label=f'Client {client_id}', linewidth=1.5)\n",
    "    \n",
    "    # è®¡ç®—å¹¶ç»˜åˆ¶å¹³å‡æŸå¤±\n",
    "    avg_loss = []\n",
    "    for round_id in range(training_loss.shape[1]):\n",
    "        round_losses = training_loss[:, round_id]\n",
    "        valid_losses = round_losses[round_losses >= 0]\n",
    "        if len(valid_losses) > 0:\n",
    "            avg_loss.append(np.mean(valid_losses))\n",
    "        else:\n",
    "            avg_loss.append(np.nan)\n",
    "    \n",
    "    valid_avg_rounds = [i+1 for i, v in enumerate(avg_loss) if not np.isnan(v)]\n",
    "    valid_avg_loss = [v for v in avg_loss if not np.isnan(v)]\n",
    "    \n",
    "    if len(valid_avg_rounds) > 0:\n",
    "        plt.plot(valid_avg_rounds, valid_avg_loss, \n",
    "                'k-', linewidth=3, label='Average Loss', marker='o', markersize=6)\n",
    "    \n",
    "    plt.xlabel('Training Round', fontsize=12)\n",
    "    plt.ylabel('Training Loss', fontsize=12)\n",
    "    plt.title('Federated Learning Training Loss', fontsize=14, fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\nğŸ“Š è®­ç»ƒç»Ÿè®¡ä¿¡æ¯:\")\n",
    "    print(f\"  åˆå§‹å¹³å‡æŸå¤±: {valid_avg_loss[0]:.4f}\")\n",
    "    print(f\"  æœ€ç»ˆå¹³å‡æŸå¤±: {valid_avg_loss[-1]:.4f}\")\n",
    "    print(f\"  æŸå¤±ä¸‹é™: {valid_avg_loss[0] - valid_avg_loss[-1]:.4f}\")\n",
    "    print(f\"  æŸå¤±ä¸‹é™ç™¾åˆ†æ¯”: {(valid_avg_loss[0] - valid_avg_loss[-1]) / valid_avg_loss[0] * 100:.2f}%\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°è®­ç»ƒæŸå¤±æ–‡ä»¶: {loss_file}\")\n",
    "    print(\"   è¯·ç¡®ä¿è®­ç»ƒå·²å®Œæˆå¹¶ä¿å­˜äº†æŸå¤±æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_output"
   },
   "source": [
    "## æ­¥éª¤9: æ£€æŸ¥è¾“å‡ºæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_files"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = training_config['output_dir']\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    print(f\"âœ… è¾“å‡ºç›®å½•å­˜åœ¨: {output_dir}\")\n",
    "    print(\"\\nğŸ“ è¾“å‡ºæ–‡ä»¶åˆ—è¡¨:\")\n",
    "    \n",
    "    for item in os.listdir(output_dir):\n",
    "        item_path = os.path.join(output_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"  ğŸ“‚ {item}/ (ç›®å½•)\")\n",
    "        else:\n",
    "            size = os.path.getsize(item_path)\n",
    "            if size < 1024:\n",
    "                size_str = f\"{size} B\"\n",
    "            elif size < 1024 * 1024:\n",
    "                size_str = f\"{size / 1024:.2f} KB\"\n",
    "            else:\n",
    "                size_str = f\"{size / (1024 * 1024):.2f} MB\"\n",
    "            print(f\"  ğŸ“„ {item} ({size_str})\")\n",
    "    \n",
    "    # è¯»å–å¹¶æ˜¾ç¤ºé…ç½®\n",
    "    config_file = os.path.join(output_dir, 'args.json')\n",
    "    if os.path.exists(config_file):\n",
    "        print(\"\\nğŸ“‹ è®­ç»ƒé…ç½®:\")\n",
    "        with open(config_file, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        print(json.dumps(config, indent=2, ensure_ascii=False))\n",
    "else:\n",
    "    print(f\"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## ğŸ’¡ ä½¿ç”¨æç¤º\n",
    "\n",
    "### å¦‚æœé‡åˆ°é—®é¢˜ï¼š\n",
    "\n",
    "1. **æ˜¾å­˜ä¸è¶³ (OOM)**ï¼š\n",
    "   - è¿›ä¸€æ­¥å‡å° `batch_size` (æ”¹ä¸º2æˆ–1)\n",
    "   - å‡å° `seq_length` (æ”¹ä¸º128)\n",
    "   - å‡å° `peft_lora_r` (æ”¹ä¸º8)\n",
    "   - å‡å° `dataset_sample` (æ”¹ä¸º2000)\n",
    "\n",
    "2. **è®­ç»ƒå¤ªæ…¢**ï¼š\n",
    "   - å‡å°‘ `num_rounds` (æ”¹ä¸º5)\n",
    "   - å‡å°‘ `max_steps` (æ”¹ä¸º3)\n",
    "   - å‡å°‘ `dataset_sample` (æ”¹ä¸º2000)\n",
    "\n",
    "3. **æ¨¡å‹ä¸‹è½½å¤±è´¥**ï¼š\n",
    "   - ç¡®ä¿å·²ç™»å½•HuggingFace: `huggingface-cli login`\n",
    "   - æˆ–è€…ä½¿ç”¨æœ¬åœ°å·²ä¸‹è½½çš„æ¨¡å‹è·¯å¾„\n",
    "\n",
    "4. **æƒ³è¦æ›´å®Œæ•´çš„è®­ç»ƒ**ï¼š\n",
    "   - å¢åŠ  `num_rounds` (æ”¹ä¸º20-50)\n",
    "   - å¢åŠ  `max_steps` (æ”¹ä¸º10)\n",
    "   - å¢åŠ  `dataset_sample` (æ”¹ä¸º10000)\n",
    "   - å¢åŠ  `num_clients` (æ”¹ä¸º10)\n",
    "\n",
    "### ä¸‹ä¸€æ­¥ï¼š\n",
    "- è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹ä¿å­˜åœ¨ `output_colab/checkpoint-*` ç›®å½•ä¸­\n",
    "- å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†\n",
    "- å¦‚éœ€è¯„ä¼°ï¼Œå¯ä»¥è¿è¡Œè¯„ä¼°è„šæœ¬ï¼ˆéœ€è¦API keyï¼‰"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
